{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df54dbd3",
   "metadata": {},
   "source": [
    "# Download Active Listings and Related Shop Info\n",
    "Etsy API limits the offset to 12,000 listings, so that is the maximum number of recently updated listings that can be accessed. (Requested 100 at a time because each request is limited to 100 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a471825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251f05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "? requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714392d6",
   "metadata": {},
   "source": [
    "### Get all listings that match keywords \"stoneware\" and \"handmade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0708f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GetListings URL and Parameters for the API\n",
    "url = \"https://openapi.etsy.com/v3/application/listings/active\"\n",
    "key = \"r8ymjsnfohuidr1wev7e4cfg\"\n",
    "keyword = \"stoneware,handmade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e8e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the dataframes\n",
    "dataframe = pd.DataFrame()\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf6cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop that increases the offset by 100 each time due to the API limitation of downloading a maximum of 100 listings at a time\n",
    "limit = 100\n",
    "offset = 0\n",
    "for i in range (1,121):\n",
    "    parameters = {\"client_id\":key, \"limit\":limit, \"offset\":offset, \"keywords\":keyword}\n",
    "    download = requests.get(url, params=parameters)\n",
    "    data = download.json()\n",
    "    if \"error\" in data.keys():\n",
    "        print(\"Maximum Offset Reached\")\n",
    "    else:\n",
    "        dataframe = pd.json_normalize(data['results'])\n",
    "        df = df.append(dataframe, ignore_index = True)\n",
    "    offset = offset + limit\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30095636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm that there are 12,000 rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5851ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL\n",
    "#write the data to a csv file\n",
    "#df.to_csv('listingsStonewareHandmade041022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf58cee",
   "metadata": {},
   "source": [
    "## Download Shop Info for all the Etsy listings in the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31bd6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: DELETE LATER You dont need this if you are doing downloading the 12,000 listings and the shop info at the same time\n",
    "#df = pd.read_csv('12000listingsStonewareHandmade032222.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee6a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the unique shop IDs\n",
    "shop_ids = df[\"shop_id\"].tolist()\n",
    "shop_list = list(set(shop_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d253fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "? shop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a223ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the dataframes\n",
    "dataframeShop = pd.DataFrame()\n",
    "dfShop = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fb777",
   "metadata": {},
   "source": [
    "# Get Shop Info\n",
    "This loop sends a request to the ETSY API to get the shop info (ratings, number of favorers, etc) for each shop that appeared in the previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a99ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop that queries the API for each unique shop ID\n",
    "limit = 100\n",
    "\n",
    "for j in range(0, len(shop_list)):\n",
    "    shop_id = str(shop_list[j])\n",
    "    url = \"https://openapi.etsy.com/v3/application/shops/\" + shop_id\n",
    "    parameters = {\"client_id\":key, \"limit\":limit}\n",
    "    download = requests.get(url, params=parameters)\n",
    "    dataShops = download.json()\n",
    "    dataframeShop = pd.json_normalize(dataShops)\n",
    "    dfShop = dfShop.append(dataframeShop, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4fb4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL\n",
    "#write the data to a csv file\n",
    "#dfShop.to_csv('ShopInfo041022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17808f3",
   "metadata": {},
   "source": [
    "## Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a9af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with just the columns I'm interested in for the listings data\n",
    "listings = df[['listing_id', 'shop_id', 'title',\n",
    "       'description', 'num_favorers',\n",
    "       'listing_type', 'tags', 'materials',\n",
    "       'style','taxonomy_id','price.amount',\n",
    "       'price.divisor', 'price.currency_code','creation_timestamp', 'ending_timestamp',\n",
    "       'original_creation_timestamp','quantity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf7a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with just the columns I'm interested in for the shops data\n",
    "shops = dfShop[['shop_id', 'shop_name', 'create_date', 'title',\n",
    "       'announcement', 'currency_code', 'is_vacation', 'vacation_message',\n",
    "       'sale_message',\n",
    "       'listing_active_count',\n",
    "       'accepts_custom_requests', 'url',\n",
    "       'num_favorers', 'languages', 'is_shop_us_based', 'transaction_sold_count',\n",
    "       'shipping_from_country_iso', 'shop_location_country_iso',\n",
    "       'review_average', 'review_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598345ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two datasets so that the shop information is added to each listing\n",
    "data = listings.merge(shops, on=\"shop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68b070a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the merged data\n",
    "#NOTE: change the date each time (maybe automate the filename with the correct date for the future)\n",
    "\n",
    "#data.to_csv('mergedData041022.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
